# ç¼“å­˜ç­–ç•¥

YYHertzæ¡†æ¶çš„å¤šå±‚ç¼“å­˜è®¾è®¡ä¸Redisé›†æˆæ–¹æ¡ˆï¼Œæ¶µç›–ç¼“å­˜æ¨¡å¼ã€ä¸€è‡´æ€§ä¿è¯ã€æ€§èƒ½ä¼˜åŒ–ç­‰æ ¸å¿ƒæŠ€æœ¯ã€‚

## ğŸ¯ ç¼“å­˜æ¶æ„æ€»è§ˆ

### å¤šå±‚ç¼“å­˜ä½“ç³»

```mermaid
graph TB
    A[ç”¨æˆ·è¯·æ±‚] --> B[åº”ç”¨å±‚ç¼“å­˜]
    B --> C[Redisç¼“å­˜å±‚]
    C --> D[æ•°æ®åº“å±‚]
    
    B --> B1[å†…å­˜ç¼“å­˜<br/>L1 Cache]
    B --> B2[æœ¬åœ°ç¼“å­˜<br/>BigCache/FreeCache]
    
    C --> C1[çƒ­ç‚¹æ•°æ®<br/>String/Hash]
    C --> C2[ä¼šè¯æ•°æ®<br/>Session Store]
    C --> C3[åˆ†å¸ƒå¼é”<br/>Redlock]
    
    D --> D1[æŸ¥è¯¢ç»“æœé›†]
    D --> D2[è®¡ç®—ç»“æœ]
    D --> D3[èšåˆæ•°æ®]
    
    style B1 fill:#e1f5fe
    style B2 fill:#f3e5f5
    style C1 fill:#fff3e0
    style C2 fill:#e8f5e8
    style C3 fill:#fce4ec
```

### ç¼“å­˜å±‚æ¬¡è®¾è®¡

| ç¼“å­˜å±‚çº§ | å­˜å‚¨ä»‹è´¨ | å®¹é‡ | å»¶è¿Ÿ | é€‚ç”¨åœºæ™¯ |
|----------|----------|------|------|----------|
| **L1 å†…å­˜ç¼“å­˜** | åº”ç”¨å†…å­˜ | 10MB-100MB | <1ms | çƒ­ç‚¹å°æ•°æ® |
| **L2 æœ¬åœ°ç¼“å­˜** | åº”ç”¨å †å¤–å†…å­˜ | 100MB-1GB | 1-5ms | é¢‘ç¹è®¿é—®æ•°æ® |
| **L3 Redisç¼“å­˜** | Rediså†…å­˜ | 1GB-100GB | 5-50ms | å…±äº«ç¼“å­˜æ•°æ® |
| **L4 æ•°æ®åº“ç¼“å­˜** | MySQL Buffer Pool | 1GB-64GB | 50-200ms | æ•°æ®åº“æŸ¥è¯¢ç¼“å­˜ |

## ğŸ”§ YYHertzç¼“å­˜é›†æˆ

### 1. ç¼“å­˜é…ç½®

#### `conf/cache.yaml`

```yaml
# Redisç¼“å­˜é…ç½®
redis:
  # ä¸»Rediså®ä¾‹
  master:
    host: "localhost"
    port: 6379
    password: "${REDIS_PASSWORD}"
    db: 0
    
    # è¿æ¥æ± é…ç½®
    pool_size: 10
    min_idle_conns: 5
    max_retries: 3
    dial_timeout: "5s"
    read_timeout: "3s"
    write_timeout: "3s"
    pool_timeout: "4s"
    idle_timeout: "5m"
    idle_check_frequency: "1m"
  
  # Redisé›†ç¾¤æ¨¡å¼
  cluster:
    enabled: false
    nodes:
      - "redis-1:6379"
      - "redis-2:6379"  
      - "redis-3:6379"
    
  # å“¨å…µæ¨¡å¼
  sentinel:
    enabled: false
    master_name: "mymaster"
    sentinels:
      - "sentinel-1:26379"
      - "sentinel-2:26379"

# æœ¬åœ°ç¼“å­˜é…ç½®
local_cache:
  # BigCacheé…ç½®
  bigcache:
    enabled: true
    shards: 1024
    life_window: "10m"
    clean_window: "5m"
    max_entries_in_window: 1000
    max_entry_size: 500
    hard_max_cache_size: 256  # MB
  
  # å†…å­˜ç¼“å­˜é…ç½®
  memory:
    enabled: true
    max_size: "64MB"
    default_expiration: "5m"
    cleanup_interval: "10m"

# ç¼“å­˜ç­–ç•¥é…ç½®
strategy:
  # é»˜è®¤è¿‡æœŸæ—¶é—´
  default_ttl: "1h"
  
  # ç¼“å­˜é¢„çƒ­
  warm_up:
    enabled: true
    parallel_workers: 5
    
  # ç¼“å­˜é›ªå´©é˜²æŠ¤
  avalanche_protection:
    enabled: true
    jitter_factor: 0.1  # TTLéšæœºå› å­
    
  # ç¼“å­˜å‡»ç©¿é˜²æŠ¤
  penetration_protection:
    enabled: true
    bloom_filter: true
    null_cache_ttl: "5m"
```

### 2. ç¼“å­˜ç®¡ç†å™¨å®ç°

```go
package cache

import (
    "context"
    "encoding/json"
    "fmt"
    "time"
    "math/rand"
    
    "github.com/go-redis/redis/v8"
    "github.com/allegro/bigcache/v3"
    "github.com/patrickmn/go-cache"
    "github.com/sirupsen/logrus"
)

// å¤šå±‚ç¼“å­˜ç®¡ç†å™¨
type CacheManager struct {
    redis    *redis.Client
    bigCache *bigcache.BigCache
    memCache *cache.Cache
    config   *CacheConfig
}

// ç¼“å­˜é…ç½®
type CacheConfig struct {
    DefaultTTL    time.Duration `yaml:"default_ttl"`
    JitterFactor  float64      `yaml:"jitter_factor"`
    NullCacheTTL  time.Duration `yaml:"null_cache_ttl"`
}

// åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
func NewCacheManager(redisClient *redis.Client, config *CacheConfig) (*CacheManager, error) {
    // BigCacheé…ç½®
    bigCacheConfig := bigcache.Config{
        Shards:             1024,
        LifeWindow:         10 * time.Minute,
        CleanWindow:        5 * time.Minute,
        MaxEntriesInWindow: 1000,
        MaxEntrySize:       500,
        HardMaxCacheSize:   256, // MB
    }
    
    bigCache, err := bigcache.NewBigCache(bigCacheConfig)
    if err != nil {
        return nil, err
    }
    
    // å†…å­˜ç¼“å­˜
    memCache := cache.New(5*time.Minute, 10*time.Minute)
    
    return &CacheManager{
        redis:    redisClient,
        bigCache: bigCache,
        memCache: memCache,
        config:   config,
    }, nil
}

// é€šç”¨ç¼“å­˜æ¥å£
type CacheKey struct {
    Key    string
    TTL    time.Duration
    Layer  CacheLayer
}

type CacheLayer int

const (
    L1Cache CacheLayer = iota // å†…å­˜ç¼“å­˜
    L2Cache                   // BigCache
    L3Cache                   // Redis
    AllLayers                 // æ‰€æœ‰å±‚çº§
)

// è·å–ç¼“å­˜
func (cm *CacheManager) Get(ctx context.Context, key string, dest interface{}) error {
    // L1 å†…å­˜ç¼“å­˜
    if data, found := cm.memCache.Get(key); found {
        return cm.unmarshal(data.([]byte), dest)
    }
    
    // L2 BigCache
    if data, err := cm.bigCache.Get(key); err == nil {
        // åŒæ­¥åˆ°L1
        cm.memCache.Set(key, data, cm.config.DefaultTTL)
        return cm.unmarshal(data, dest)
    }
    
    // L3 Redisç¼“å­˜
    data, err := cm.redis.Get(ctx, key).Bytes()
    if err != nil && err != redis.Nil {
        return err
    }
    
    if err != redis.Nil {
        // åŒæ­¥åˆ°L1å’ŒL2
        cm.memCache.Set(key, data, cm.config.DefaultTTL)
        cm.bigCache.Set(key, data)
        return cm.unmarshal(data, dest)
    }
    
    return ErrCacheNotFound
}

// è®¾ç½®ç¼“å­˜
func (cm *CacheManager) Set(ctx context.Context, key string, value interface{}, ttl time.Duration) error {
    data, err := cm.marshal(value)
    if err != nil {
        return err
    }
    
    // æ·»åŠ TTLæŠ–åŠ¨ï¼Œé˜²æ­¢ç¼“å­˜é›ªå´©
    jitteredTTL := cm.addJitter(ttl)
    
    // è®¾ç½®åˆ°æ‰€æœ‰å±‚çº§
    cm.memCache.Set(key, data, jitteredTTL)
    cm.bigCache.Set(key, data)
    
    return cm.redis.Set(ctx, key, data, jitteredTTL).Err()
}

// TTLæŠ–åŠ¨
func (cm *CacheManager) addJitter(ttl time.Duration) time.Duration {
    if cm.config.JitterFactor <= 0 {
        return ttl
    }
    
    jitter := time.Duration(rand.Float64() * float64(ttl) * cm.config.JitterFactor)
    return ttl + jitter
}

// åˆ é™¤ç¼“å­˜
func (cm *CacheManager) Delete(ctx context.Context, key string) error {
    cm.memCache.Delete(key)
    cm.bigCache.Delete(key)
    return cm.redis.Del(ctx, key).Err()
}

// åºåˆ—åŒ–
func (cm *CacheManager) marshal(v interface{}) ([]byte, error) {
    return json.Marshal(v)
}

// ååºåˆ—åŒ–
func (cm *CacheManager) unmarshal(data []byte, v interface{}) error {
    return json.Unmarshal(data, v)
}
```

## ğŸ¨ ç¼“å­˜æ¨¡å¼å®ç°

### 1. Cache-Asideæ¨¡å¼

```go
// Cache-Asideç¼“å­˜æ¨¡å¼
func (c *UserController) GetUserByID(ctx context.Context, userID int64) (*User, error) {
    cacheKey := fmt.Sprintf("user:%d", userID)
    
    // 1. å…ˆæŸ¥ç¼“å­˜
    var user User
    err := c.cacheManager.Get(ctx, cacheKey, &user)
    if err == nil {
        // ç¼“å­˜å‘½ä¸­
        return &user, nil
    }
    
    if err != ErrCacheNotFound {
        // ç¼“å­˜æŸ¥è¯¢å‡ºé”™ï¼Œè®°å½•æ—¥å¿—ä½†ç»§ç»­æŸ¥æ•°æ®åº“
        logrus.WithError(err).Warn("ç¼“å­˜æŸ¥è¯¢å¤±è´¥")
    }
    
    // 2. ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“
    err = c.db.First(&user, userID).Error
    if err != nil {
        if errors.Is(err, gorm.ErrRecordNotFound) {
            // ç¼“å­˜ç©ºå€¼ï¼Œé˜²æ­¢ç¼“å­˜å‡»ç©¿
            c.cacheManager.Set(ctx, cacheKey, nil, c.config.NullCacheTTL)
        }
        return nil, err
    }
    
    // 3. å°†ç»“æœå†™å…¥ç¼“å­˜
    err = c.cacheManager.Set(ctx, cacheKey, &user, time.Hour)
    if err != nil {
        logrus.WithError(err).Warn("ç¼“å­˜å†™å…¥å¤±è´¥")
    }
    
    return &user, nil
}

// æ›´æ–°æ—¶åˆ é™¤ç¼“å­˜
func (c *UserController) UpdateUser(ctx context.Context, userID int64, updates map[string]interface{}) error {
    err := c.db.Model(&User{}).Where("id = ?", userID).Updates(updates).Error
    if err != nil {
        return err
    }
    
    // åˆ é™¤ç›¸å…³ç¼“å­˜
    cacheKey := fmt.Sprintf("user:%d", userID)
    c.cacheManager.Delete(ctx, cacheKey)
    
    return nil
}
```

### 2. Write-Throughæ¨¡å¼

```go
// Write-Throughç¼“å­˜æ¨¡å¼
func (c *UserController) SaveUserWithCache(ctx context.Context, user *User) error {
    // 1. å†™å…¥æ•°æ®åº“
    err := c.db.Save(user).Error
    if err != nil {
        return err
    }
    
    // 2. åŒæ­¥å†™å…¥ç¼“å­˜
    cacheKey := fmt.Sprintf("user:%d", user.ID)
    err = c.cacheManager.Set(ctx, cacheKey, user, time.Hour)
    if err != nil {
        // ç¼“å­˜å†™å…¥å¤±è´¥ï¼Œè®°å½•æ—¥å¿—ä½†ä¸å½±å“ä¸»æµç¨‹
        logrus.WithError(err).Error("Write-Throughç¼“å­˜å†™å…¥å¤±è´¥")
    }
    
    return nil
}
```

### 3. Write-Behindæ¨¡å¼

```go
// Write-Behindå¼‚æ­¥å†™å…¥é˜Ÿåˆ—
type WriteBackQueue struct {
    queue   chan *WriteBackItem
    manager *CacheManager
    db      *gorm.DB
}

type WriteBackItem struct {
    Key   string
    Value interface{}
    Op    WriteOp
}

type WriteOp int

const (
    OpInsert WriteOp = iota
    OpUpdate
    OpDelete
)

func NewWriteBackQueue(manager *CacheManager, db *gorm.DB, workers int) *WriteBackQueue {
    wbq := &WriteBackQueue{
        queue:   make(chan *WriteBackItem, 1000),
        manager: manager,
        db:      db,
    }
    
    // å¯åŠ¨åå°å†™å…¥åç¨‹
    for i := 0; i < workers; i++ {
        go wbq.worker()
    }
    
    return wbq
}

func (wbq *WriteBackQueue) worker() {
    for item := range wbq.queue {
        switch item.Op {
        case OpInsert:
            wbq.db.Create(item.Value)
        case OpUpdate:
            wbq.db.Save(item.Value)
        case OpDelete:
            wbq.db.Delete(item.Value)
        }
    }
}

// Write-Behindæ›´æ–°
func (c *UserController) UpdateUserAsync(ctx context.Context, user *User) error {
    // 1. ç«‹å³æ›´æ–°ç¼“å­˜
    cacheKey := fmt.Sprintf("user:%d", user.ID)
    err := c.cacheManager.Set(ctx, cacheKey, user, time.Hour)
    if err != nil {
        return err
    }
    
    // 2. å¼‚æ­¥å†™å…¥æ•°æ®åº“
    c.writeBackQueue.queue <- &WriteBackItem{
        Key:   cacheKey,
        Value: user,
        Op:    OpUpdate,
    }
    
    return nil
}
```

## ğŸ”’ åˆ†å¸ƒå¼ç¼“å­˜ä¸€è‡´æ€§

### 1. åˆ†å¸ƒå¼é”å®ç°

```go
package lock

import (
    "context"
    "time"
    "github.com/go-redis/redis/v8"
)

// åˆ†å¸ƒå¼é”
type DistributedLock struct {
    redis  *redis.Client
    key    string
    value  string
    expiry time.Duration
}

// è·å–é”
func (dl *DistributedLock) Lock(ctx context.Context) error {
    // ä½¿ç”¨SETå‘½ä»¤çš„NXå’ŒEXé€‰é¡¹å®ç°åŸå­æ“ä½œ
    result, err := dl.redis.SetNX(ctx, dl.key, dl.value, dl.expiry).Result()
    if err != nil {
        return err
    }
    
    if !result {
        return ErrLockFailed
    }
    
    return nil
}

// é‡Šæ”¾é”
func (dl *DistributedLock) Unlock(ctx context.Context) error {
    // Luaè„šæœ¬ç¡®ä¿åŸå­æ€§é‡Šæ”¾
    luaScript := `
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
        else
            return 0
        end
    `
    
    result, err := dl.redis.Eval(ctx, luaScript, []string{dl.key}, dl.value).Result()
    if err != nil {
        return err
    }
    
    if result.(int64) == 0 {
        return ErrLockNotOwned
    }
    
    return nil
}

// ä½¿ç”¨åˆ†å¸ƒå¼é”çš„ç¼“å­˜æ›´æ–°
func (c *UserController) UpdateUserWithLock(ctx context.Context, userID int64, updates map[string]interface{}) error {
    lockKey := fmt.Sprintf("lock:user:%d", userID)
    lock := &DistributedLock{
        redis:  c.redis,
        key:    lockKey,
        value:  generateLockValue(),
        expiry: 30 * time.Second,
    }
    
    // è·å–é”
    err := lock.Lock(ctx)
    if err != nil {
        return err
    }
    defer lock.Unlock(ctx)
    
    // åœ¨é”ä¿æŠ¤ä¸‹æ›´æ–°æ•°æ®
    err = c.db.Model(&User{}).Where("id = ?", userID).Updates(updates).Error
    if err != nil {
        return err
    }
    
    // åˆ é™¤ç¼“å­˜
    cacheKey := fmt.Sprintf("user:%d", userID)
    return c.cacheManager.Delete(ctx, cacheKey)
}
```

### 2. ç¼“å­˜æ›´æ–°ç­–ç•¥

```go
// ç¼“å­˜æ›´æ–°ç­–ç•¥æ¥å£
type CacheUpdateStrategy interface {
    Update(ctx context.Context, key string, value interface{}) error
}

// å»¶æ—¶åŒåˆ ç­–ç•¥
type DelayedDoubleDeleteStrategy struct {
    cacheManager *CacheManager
    delay        time.Duration
}

func (s *DelayedDoubleDeleteStrategy) Update(ctx context.Context, key string, value interface{}) error {
    // 1. å…ˆåˆ é™¤ç¼“å­˜
    s.cacheManager.Delete(ctx, key)
    
    // 2. æ›´æ–°æ•°æ®åº“
    // (è¿™é‡Œåº”è¯¥æ˜¯å®é™…çš„æ•°æ®åº“æ›´æ–°é€»è¾‘)
    
    // 3. å»¶æ—¶åå†åˆ é™¤ç¼“å­˜
    go func() {
        time.Sleep(s.delay)
        s.cacheManager.Delete(context.Background(), key)
    }()
    
    return nil
}

// æ¶ˆæ¯é˜Ÿåˆ—ç­–ç•¥
type MQCacheStrategy struct {
    cacheManager *CacheManager
    mqProducer   MQProducer
}

func (s *MQCacheStrategy) Update(ctx context.Context, key string, value interface{}) error {
    // å‘é€ç¼“å­˜æ›´æ–°æ¶ˆæ¯
    message := CacheUpdateMessage{
        Key:   key,
        Value: value,
        Op:    "delete",
    }
    
    return s.mqProducer.Send("cache_update", message)
}
```

## ğŸ“Š ç¼“å­˜ç›‘æ§ä¸æŒ‡æ ‡

### 1. ç¼“å­˜æŒ‡æ ‡æ”¶é›†

```go
package metrics

import (
    "github.com/prometheus/client_golang/prometheus"
    "time"
)

// ç¼“å­˜æŒ‡æ ‡
var (
    CacheHits = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "cache_hits_total",
            Help: "Cache hits total",
        },
        []string{"layer", "key_pattern"},
    )
    
    CacheMisses = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "cache_misses_total", 
            Help: "Cache misses total",
        },
        []string{"layer", "key_pattern"},
    )
    
    CacheLatency = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "cache_operation_duration_seconds",
            Help: "Cache operation latency",
            Buckets: []float64{0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0},
        },
        []string{"operation", "layer"},
    )
)

// ç¼“å­˜æŒ‡æ ‡ä¸­é—´ä»¶
func CacheMetricsMiddleware(cm *CacheManager) *MetricsMiddleware {
    return &MetricsMiddleware{cacheManager: cm}
}

type MetricsMiddleware struct {
    cacheManager *CacheManager
}

func (m *MetricsMiddleware) Get(key string, dest interface{}) error {
    start := time.Now()
    defer func() {
        CacheLatency.WithLabelValues("get", "redis").Observe(time.Since(start).Seconds())
    }()
    
    err := m.cacheManager.Get(context.Background(), key, dest)
    if err == nil {
        CacheHits.WithLabelValues("redis", getKeyPattern(key)).Inc()
    } else {
        CacheMisses.WithLabelValues("redis", getKeyPattern(key)).Inc()
    }
    
    return err
}

func getKeyPattern(key string) string {
    // æå–é”®æ¨¡å¼ï¼Œå¦‚ "user:123" -> "user:*"
    parts := strings.Split(key, ":")
    if len(parts) >= 2 {
        return parts[0] + ":*"
    }
    return "other"
}
```

### 2. ç¼“å­˜å¥åº·æ£€æŸ¥

```go
// ç¼“å­˜å¥åº·æ£€æŸ¥
type CacheHealthChecker struct {
    redis        *redis.Client
    cacheManager *CacheManager
}

func (chc *CacheHealthChecker) CheckHealth(ctx context.Context) error {
    // 1. Redisè¿æ¥æ£€æŸ¥
    _, err := chc.redis.Ping(ctx).Result()
    if err != nil {
        return fmt.Errorf("Redisè¿æ¥å¤±è´¥: %w", err)
    }
    
    // 2. ç¼“å­˜è¯»å†™æµ‹è¯•
    testKey := "health_check_" + generateRandomString(8)
    testValue := map[string]interface{}{
        "timestamp": time.Now(),
        "test":      true,
    }
    
    // å†™å…¥æµ‹è¯•
    err = chc.cacheManager.Set(ctx, testKey, testValue, time.Minute)
    if err != nil {
        return fmt.Errorf("ç¼“å­˜å†™å…¥å¤±è´¥: %w", err)
    }
    
    // è¯»å–æµ‹è¯•
    var result map[string]interface{}
    err = chc.cacheManager.Get(ctx, testKey, &result)
    if err != nil {
        return fmt.Errorf("ç¼“å­˜è¯»å–å¤±è´¥: %w", err)
    }
    
    // æ¸…ç†æµ‹è¯•æ•°æ®
    chc.cacheManager.Delete(ctx, testKey)
    
    return nil
}

// å®šæœŸå¥åº·æ£€æŸ¥
func (chc *CacheHealthChecker) StartHealthCheck(interval time.Duration) {
    ticker := time.NewTicker(interval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ticker.C:
            ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
            err := chc.CheckHealth(ctx)
            cancel()
            
            if err != nil {
                logrus.WithError(err).Error("ç¼“å­˜å¥åº·æ£€æŸ¥å¤±è´¥")
                // å‘é€å‘Šè­¦
                alerting.SendAlert("CacheHealthCheckFailed", map[string]interface{}{
                    "error": err.Error(),
                })
            }
        }
    }
}
```

## ğŸš€ ç¼“å­˜æœ€ä½³å®è·µ

### 1. ç¼“å­˜é¢„çƒ­

```go
// ç¼“å­˜é¢„çƒ­æœåŠ¡
type CacheWarmupService struct {
    cacheManager *CacheManager
    db           *gorm.DB
    workers      int
}

func (cws *CacheWarmupService) WarmupUsers() error {
    // è·å–çƒ­ç‚¹ç”¨æˆ·IDåˆ—è¡¨
    var userIDs []int64
    err := cws.db.Model(&User{}).
        Where("last_login_at > ?", time.Now().AddDate(0, 0, -7)).
        Order("last_login_at DESC").
        Limit(1000).
        Pluck("id", &userIDs).Error
    if err != nil {
        return err
    }
    
    // å¹¶å‘é¢„çƒ­
    jobs := make(chan int64, len(userIDs))
    for _, userID := range userIDs {
        jobs <- userID
    }
    close(jobs)
    
    var wg sync.WaitGroup
    for i := 0; i < cws.workers; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for userID := range jobs {
                cws.warmupUser(userID)
            }
        }()
    }
    
    wg.Wait()
    return nil
}

func (cws *CacheWarmupService) warmupUser(userID int64) {
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()
    
    var user User
    err := cws.db.First(&user, userID).Error
    if err != nil {
        return
    }
    
    cacheKey := fmt.Sprintf("user:%d", userID)
    cws.cacheManager.Set(ctx, cacheKey, &user, time.Hour)
}
```

### 2. ç¼“å­˜åˆ†ç‰‡ç­–ç•¥

```go
// ä¸€è‡´æ€§å“ˆå¸Œåˆ†ç‰‡
type ConsistentHashSharding struct {
    nodes []string
    ring  map[uint32]string
}

func NewConsistentHashSharding(nodes []string) *ConsistentHashSharding {
    chs := &ConsistentHashSharding{
        nodes: nodes,
        ring:  make(map[uint32]string),
    }
    
    // æ„å»ºå“ˆå¸Œç¯
    for _, node := range nodes {
        for i := 0; i < 150; i++ { // è™šæ‹ŸèŠ‚ç‚¹æ•°
            virtualKey := fmt.Sprintf("%s:%d", node, i)
            hash := crc32.ChecksumIEEE([]byte(virtualKey))
            chs.ring[hash] = node
        }
    }
    
    return chs
}

func (chs *ConsistentHashSharding) GetNode(key string) string {
    if len(chs.ring) == 0 {
        return ""
    }
    
    hash := crc32.ChecksumIEEE([]byte(key))
    
    // é¡ºæ—¶é’ˆæ‰¾åˆ°ç¬¬ä¸€ä¸ªèŠ‚ç‚¹
    for h, node := range chs.ring {
        if h >= hash {
            return node
        }
    }
    
    // å¦‚æœæ²¡æ‰¾åˆ°ï¼Œè¿”å›ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆç¯å½¢ï¼‰
    var minHash uint32 = math.MaxUint32
    var minNode string
    for h, node := range chs.ring {
        if h < minHash {
            minHash = h
            minNode = node
        }
    }
    
    return minNode
}
```

### 3. ç¼“å­˜å¤±æ•ˆç­–ç•¥

```go
// æ ‡ç­¾å¼ç¼“å­˜å¤±æ•ˆ
type TaggedCache struct {
    cacheManager *CacheManager
    redis        *redis.Client
}

// ä¸ºç¼“å­˜æ·»åŠ æ ‡ç­¾
func (tc *TaggedCache) SetWithTags(ctx context.Context, key string, value interface{}, ttl time.Duration, tags []string) error {
    // è®¾ç½®ç¼“å­˜
    err := tc.cacheManager.Set(ctx, key, value, ttl)
    if err != nil {
        return err
    }
    
    // ä¸ºæ¯ä¸ªæ ‡ç­¾å…³è”ç¼“å­˜é”®
    for _, tag := range tags {
        tagKey := fmt.Sprintf("tag:%s", tag)
        tc.redis.SAdd(ctx, tagKey, key)
        tc.redis.Expire(ctx, tagKey, ttl+time.Hour) // æ ‡ç­¾è¿‡æœŸæ—¶é—´ç¨é•¿
    }
    
    return nil
}

// æ ¹æ®æ ‡ç­¾åˆ é™¤ç¼“å­˜
func (tc *TaggedCache) InvalidateByTag(ctx context.Context, tag string) error {
    tagKey := fmt.Sprintf("tag:%s", tag)
    
    // è·å–æ‰€æœ‰ç›¸å…³çš„ç¼“å­˜é”®
    keys, err := tc.redis.SMembers(ctx, tagKey).Result()
    if err != nil {
        return err
    }
    
    // åˆ é™¤æ‰€æœ‰ç›¸å…³ç¼“å­˜
    for _, key := range keys {
        tc.cacheManager.Delete(ctx, key)
    }
    
    // åˆ é™¤æ ‡ç­¾é›†åˆ
    return tc.redis.Del(ctx, tagKey).Err()
}

// ä½¿ç”¨ç¤ºä¾‹
func (c *UserController) UpdateUserProfile(ctx context.Context, userID int64) error {
    // æ›´æ–°ç”¨æˆ·æ•°æ®åï¼Œä½¿ç¼“å­˜å¤±æ•ˆ
    tags := []string{
        fmt.Sprintf("user:%d", userID),
        "user_profiles",
        "user_list",
    }
    
    for _, tag := range tags {
        c.taggedCache.InvalidateByTag(ctx, tag)
    }
    
    return nil
}
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡æ“ä½œ

```go
// æ‰¹é‡ç¼“å­˜æ“ä½œ
func (cm *CacheManager) MGet(ctx context.Context, keys []string) (map[string]interface{}, error) {
    result := make(map[string]interface{})
    
    // Redisæ‰¹é‡è·å–
    values, err := cm.redis.MGet(ctx, keys...).Result()
    if err != nil {
        return nil, err
    }
    
    for i, key := range keys {
        if values[i] != nil {
            result[key] = values[i]
        }
    }
    
    return result, nil
}

func (cm *CacheManager) MSet(ctx context.Context, pairs map[string]interface{}, ttl time.Duration) error {
    // æ„å»ºRediså‚æ•°
    args := make([]interface{}, 0, len(pairs)*2)
    for key, value := range pairs {
        data, err := cm.marshal(value)
        if err != nil {
            return err
        }
        args = append(args, key, data)
    }
    
    // æ‰¹é‡è®¾ç½®
    err := cm.redis.MSet(ctx, args...).Err()
    if err != nil {
        return err
    }
    
    // æ‰¹é‡è®¾ç½®è¿‡æœŸæ—¶é—´
    pipe := cm.redis.Pipeline()
    for key := range pairs {
        pipe.Expire(ctx, key, ttl)
    }
    _, err = pipe.Exec(ctx)
    
    return err
}
```

### 2. Pipelineä¼˜åŒ–

```go
// Redis Pipelineæ‰¹é‡æ“ä½œ
func (c *UserController) BatchUpdateUserCache(ctx context.Context, users []User) error {
    pipe := c.redis.Pipeline()
    
    for _, user := range users {
        key := fmt.Sprintf("user:%d", user.ID)
        data, _ := json.Marshal(user)
        pipe.Set(ctx, key, data, time.Hour)
        
        // åŒæ—¶æ›´æ–°ç”¨æˆ·åˆ—è¡¨ç¼“å­˜
        pipe.ZAdd(ctx, "user_list", &redis.Z{
            Score:  float64(user.ID),
            Member: user.ID,
        })
    }
    
    // æ‰§è¡Œæ‰€æœ‰å‘½ä»¤
    _, err := pipe.Exec(ctx)
    return err
}
```

## ğŸ”— ç›¸å…³èµ„æº

- **[MyBatisæ€§èƒ½ä¼˜åŒ–](./mybatis-performance.md)** - æ•°æ®è®¿é—®å±‚ç¼“å­˜é›†æˆ
- **[æ•°æ®åº“è°ƒä¼˜](./database-tuning.md)** - æ•°æ®åº“æŸ¥è¯¢ç»“æœç¼“å­˜
- **[ç›‘æ§å‘Šè­¦](./monitoring-alerting.md)** - ç¼“å­˜ç³»ç»Ÿç›‘æ§æŒ‡æ ‡

---

**æœ‰æ•ˆçš„ç¼“å­˜ç­–ç•¥æ˜¯é«˜æ€§èƒ½ç³»ç»Ÿçš„å…³é”®** - é€šè¿‡å¤šå±‚ç¼“å­˜ã€åˆç†çš„å¤±æ•ˆæœºåˆ¶å’Œç›‘æ§ä½“ç³»ï¼Œå¤§å¹…æå‡åº”ç”¨å“åº”é€Ÿåº¦ï¼ğŸš€
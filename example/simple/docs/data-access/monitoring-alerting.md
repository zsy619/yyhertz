# ç›‘æ§å‘Šè­¦

YYHertzæ¡†æ¶çš„å®Œæ•´å¯è§‚æµ‹æ€§è§£å†³æ–¹æ¡ˆï¼ŒåŒ…å«æŒ‡æ ‡æ”¶é›†ã€é“¾è·¯è¿½è¸ªã€æ—¥å¿—èšåˆã€å‘Šè­¦é€šçŸ¥ç­‰æ ¸å¿ƒèƒ½åŠ›ã€‚

## ğŸ¯ å¯è§‚æµ‹æ€§æ¶æ„

### ä¸‰å¤§æ”¯æŸ±ä½“ç³»

```mermaid
graph TB
    A[åº”ç”¨ç³»ç»Ÿ] --> B[Metrics æŒ‡æ ‡]
    A --> C[Tracing é“¾è·¯]
    A --> D[Logging æ—¥å¿—]
    
    B --> B1[Prometheus]
    B --> B2[Grafana]
    B --> B3[AlertManager]
    
    C --> C1[Jaeger]
    C --> C2[Zipkin]
    C --> C3[OpenTelemetry]
    
    D --> D1[ELK Stack]
    D --> D2[Fluentd]
    D --> D3[Loki]
    
    B3 --> E[é€šçŸ¥æ¸ é“]
    E --> E1[é’‰é’‰/ä¼å¾®]
    E --> E2[é‚®ä»¶]
    E --> E3[çŸ­ä¿¡]
    
    style B fill:#e3f2fd
    style C fill:#f3e5f5
    style D fill:#e8f5e8
    style E fill:#fff3e0
```

### ç›‘æ§å±‚æ¬¡ç»“æ„

| ç›‘æ§å±‚çº§ | ç›‘æ§å¯¹è±¡ | å…³é”®æŒ‡æ ‡ | å‘Šè­¦é˜ˆå€¼ | å“åº”æ—¶é—´ |
|----------|----------|----------|----------|----------|
| **åŸºç¡€è®¾æ–½** | æœåŠ¡å™¨ã€ç½‘ç»œ | CPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œ | CPU>80%, å†…å­˜>85% | ç«‹å³ |
| **ä¸­é—´ä»¶** | Redisã€MySQLã€MQ | è¿æ¥æ•°ã€QPSã€å»¶è¿Ÿ | è¿æ¥>80%, å»¶è¿Ÿ>100ms | 2åˆ†é’Ÿ |
| **åº”ç”¨æœåŠ¡** | HTTPã€RPC | è¯·æ±‚é‡ã€é”™è¯¯ç‡ã€å“åº”æ—¶é—´ | é”™è¯¯ç‡>5%, RT>1s | 1åˆ†é’Ÿ |
| **ä¸šåŠ¡åŠŸèƒ½** | ç”¨æˆ·è¡Œä¸ºã€ä¸šåŠ¡æµç¨‹ | è½¬åŒ–ç‡ã€æˆåŠŸç‡ | æ ¹æ®ä¸šåŠ¡å®šåˆ¶ | 5åˆ†é’Ÿ |

## ğŸ“Š PrometheusæŒ‡æ ‡æ”¶é›†

### 1. YYHertzæ¡†æ¶æŒ‡æ ‡é›†æˆ

#### `framework/monitoring/prometheus.go`

```go
package monitoring

import (
    "strconv"
    "time"
    
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promhttp"
    "github.com/cloudwego/hertz/pkg/app"
    "github.com/cloudwego/hertz/pkg/common/hlog"
)

// PrometheusæŒ‡æ ‡å®šä¹‰
var (
    // HTTPè¯·æ±‚æŒ‡æ ‡
    HTTPRequestsTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "path", "status_code"},
    )
    
    HTTPRequestDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "http_request_duration_seconds",
            Help: "HTTP request duration",
            Buckets: []float64{0.01, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10},
        },
        []string{"method", "path"},
    )
    
    HTTPRequestsInFlight = prometheus.NewGauge(
        prometheus.GaugeOpts{
            Name: "http_requests_in_flight",
            Help: "Current number of HTTP requests being processed",
        },
    )
    
    // æ•°æ®åº“æŒ‡æ ‡
    DBConnectionsInUse = prometheus.NewGauge(
        prometheus.GaugeOpts{
            Name: "db_connections_in_use",
            Help: "Number of database connections in use",
        },
    )
    
    DBQueryDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "db_query_duration_seconds",
            Help: "Database query duration",
            Buckets: []float64{0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0},
        },
        []string{"operation", "table"},
    )
    
    // RedisæŒ‡æ ‡
    RedisOperationDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "redis_operation_duration_seconds",
            Help: "Redis operation duration",
            Buckets: []float64{0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0},
        },
        []string{"command"},
    )
    
    // è‡ªå®šä¹‰ä¸šåŠ¡æŒ‡æ ‡
    UserLoginTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "user_login_total",
            Help: "Total user login attempts",
        },
        []string{"status", "method"},
    )
    
    ActiveUsers = prometheus.NewGauge(
        prometheus.GaugeOpts{
            Name: "active_users",
            Help: "Current number of active users",
        },
    )
)

// æ³¨å†Œæ‰€æœ‰æŒ‡æ ‡
func init() {
    prometheus.MustRegister(
        HTTPRequestsTotal,
        HTTPRequestDuration,
        HTTPRequestsInFlight,
        DBConnectionsInUse,
        DBQueryDuration,
        RedisOperationDuration,
        UserLoginTotal,
        ActiveUsers,
    )
}

// Prometheusç›‘æ§ä¸­é—´ä»¶
func PrometheusMiddleware() app.HandlerFunc {
    return func(ctx context.Context, c *app.RequestContext) {
        start := time.Now()
        path := string(c.Path())
        method := string(c.Method())
        
        // å¢åŠ æ­£åœ¨å¤„ç†çš„è¯·æ±‚æ•°
        HTTPRequestsInFlight.Inc()
        defer HTTPRequestsInFlight.Dec()
        
        // å¤„ç†è¯·æ±‚
        c.Next(ctx)
        
        // è®°å½•æŒ‡æ ‡
        duration := time.Since(start).Seconds()
        statusCode := strconv.Itoa(c.Response.StatusCode())
        
        HTTPRequestsTotal.WithLabelValues(method, path, statusCode).Inc()
        HTTPRequestDuration.WithLabelValues(method, path).Observe(duration)
        
        // è®°å½•æ…¢è¯·æ±‚
        if duration > 1.0 {
            hlog.CtxWarnf(ctx, "æ…¢è¯·æ±‚: %s %s è€—æ—¶: %.3fs", method, path, duration)
        }
    }
}

// ä¸šåŠ¡æŒ‡æ ‡è®°å½•å™¨
type BusinessMetrics struct{}

// è®°å½•ç”¨æˆ·ç™»å½•
func (bm *BusinessMetrics) RecordUserLogin(status, method string) {
    UserLoginTotal.WithLabelValues(status, method).Inc()
}

// æ›´æ–°æ´»è·ƒç”¨æˆ·æ•°
func (bm *BusinessMetrics) UpdateActiveUsers(count float64) {
    ActiveUsers.Set(count)
}

// å¯åŠ¨æŒ‡æ ‡æ”¶é›†å®šæ—¶ä»»åŠ¡
func (bm *BusinessMetrics) StartMetricsCollection() {
    ticker := time.NewTicker(30 * time.Second)
    go func() {
        for {
            select {
            case <-ticker.C:
                bm.collectBusinessMetrics()
            }
        }
    }()
}

func (bm *BusinessMetrics) collectBusinessMetrics() {
    // è¿™é‡Œå®ç°å…·ä½“çš„ä¸šåŠ¡æŒ‡æ ‡æ”¶é›†é€»è¾‘
    // ä¾‹å¦‚ï¼šæŸ¥è¯¢æ•°æ®åº“è·å–æ´»è·ƒç”¨æˆ·æ•°
    // activeCount := getUserActiveCount()
    // ActiveUsers.Set(float64(activeCount))
}
```

### 2. è‡ªå®šä¹‰æŒ‡æ ‡æ”¶é›†å™¨

```go
// è‡ªå®šä¹‰æ”¶é›†å™¨
type CustomCollector struct {
    db          *gorm.DB
    redis       *redis.Client
    metricDescs []*prometheus.Desc
}

func NewCustomCollector(db *gorm.DB, redis *redis.Client) *CustomCollector {
    return &CustomCollector{
        db:    db,
        redis: redis,
        metricDescs: []*prometheus.Desc{
            prometheus.NewDesc(
                "yyhertz_total_users",
                "Total number of registered users",
                nil, nil,
            ),
            prometheus.NewDesc(
                "yyhertz_online_users",
                "Number of online users",
                nil, nil,
            ),
            prometheus.NewDesc(
                "yyhertz_orders_today",
                "Number of orders created today",
                nil, nil,
            ),
        },
    }
}

// å®ç°Collectoræ¥å£
func (c *CustomCollector) Describe(ch chan<- *prometheus.Desc) {
    for _, desc := range c.metricDescs {
        ch <- desc
    }
}

func (c *CustomCollector) Collect(ch chan<- prometheus.Metric) {
    // æ”¶é›†ç”¨æˆ·æ€»æ•°
    var totalUsers int64
    c.db.Model(&User{}).Count(&totalUsers)
    ch <- prometheus.MustNewConstMetric(
        c.metricDescs[0],
        prometheus.GaugeValue,
        float64(totalUsers),
    )
    
    // æ”¶é›†åœ¨çº¿ç”¨æˆ·æ•°
    onlineUsers, _ := c.redis.SCard(context.Background(), "online_users").Result()
    ch <- prometheus.MustNewConstMetric(
        c.metricDescs[1],
        prometheus.GaugeValue,
        float64(onlineUsers),
    )
    
    // æ”¶é›†ä»Šæ—¥è®¢å•æ•°
    var todayOrders int64
    today := time.Now().Format("2006-01-02")
    c.db.Model(&Order{}).
        Where("DATE(created_at) = ?", today).
        Count(&todayOrders)
    ch <- prometheus.MustNewConstMetric(
        c.metricDescs[2],
        prometheus.GaugeValue,
        float64(todayOrders),
    )
}
```

## ğŸ” é“¾è·¯è¿½è¸ªé›†æˆ

### 1. OpenTelemetryé…ç½®

```go
package tracing

import (
    "context"
    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/exporters/jaeger"
    "go.opentelemetry.io/otel/sdk/resource"
    "go.opentelemetry.io/otel/sdk/trace"
    "go.opentelemetry.io/otel/semconv/v1.4.0"
)

// åˆå§‹åŒ–é“¾è·¯è¿½è¸ª
func InitTracing(serviceName, jaegerEndpoint string) (func(), error) {
    // åˆ›å»ºJaegerå¯¼å‡ºå™¨
    exp, err := jaeger.New(jaeger.WithCollectorEndpoint(
        jaeger.WithEndpoint(jaegerEndpoint),
    ))
    if err != nil {
        return nil, err
    }
    
    // åˆ›å»ºTracerProvider
    tp := trace.NewTracerProvider(
        trace.WithBatcher(exp),
        trace.WithResource(resource.NewWithAttributes(
            semconv.SchemaURL,
            semconv.ServiceNameKey.String(serviceName),
            semconv.ServiceVersionKey.String("1.0.0"),
        )),
    )
    
    otel.SetTracerProvider(tp)
    
    return func() {
        tp.Shutdown(context.Background())
    }, nil
}

// é“¾è·¯è¿½è¸ªä¸­é—´ä»¶
func TracingMiddleware(serviceName string) app.HandlerFunc {
    tracer := otel.Tracer(serviceName)
    
    return func(ctx context.Context, c *app.RequestContext) {
        spanCtx, span := tracer.Start(ctx, string(c.Path()))
        defer span.End()
        
        // è®¾ç½®spanå±æ€§
        span.SetAttributes(
            attribute.String("http.method", string(c.Method())),
            attribute.String("http.url", string(c.URI().FullURI())),
            attribute.String("http.user_agent", string(c.UserAgent())),
        )
        
        // ä¼ é€’traceä¸Šä¸‹æ–‡
        c.Set("trace_context", spanCtx)
        
        c.Next(spanCtx)
        
        // è®¾ç½®å“åº”å±æ€§
        span.SetAttributes(
            attribute.Int("http.status_code", c.Response.StatusCode()),
            attribute.Int64("http.response_size", int64(c.Response.Header.ContentLength())),
        )
    }
}

// æ•°æ®åº“é“¾è·¯è¿½è¸ª
func DatabaseTracingPlugin(serviceName string) gorm.Plugin {
    return &dbTracingPlugin{
        tracer: otel.Tracer(serviceName),
    }
}

type dbTracingPlugin struct {
    tracer trace.Tracer
}

func (p *dbTracingPlugin) Name() string {
    return "tracing"
}

func (p *dbTracingPlugin) Initialize(db *gorm.DB) error {
    db.Callback().Query().Before("gorm:query").Register("tracing:before_query", p.beforeQuery)
    db.Callback().Query().After("gorm:query").Register("tracing:after_query", p.afterQuery)
    return nil
}

func (p *dbTracingPlugin) beforeQuery(db *gorm.DB) {
    ctx := db.Statement.Context
    _, span := p.tracer.Start(ctx, "db.query")
    
    span.SetAttributes(
        attribute.String("db.statement", db.Statement.SQL.String()),
        attribute.String("db.table", db.Statement.Table),
        attribute.String("db.operation", "select"),
    )
    
    db.Statement.Context = trace.ContextWithSpan(ctx, span)
}

func (p *dbTracingPlugin) afterQuery(db *gorm.DB) {
    span := trace.SpanFromContext(db.Statement.Context)
    defer span.End()
    
    if db.Error != nil {
        span.SetAttributes(attribute.String("db.error", db.Error.Error()))
        span.SetStatus(codes.Error, db.Error.Error())
    } else {
        span.SetAttributes(attribute.Int64("db.rows_affected", db.RowsAffected))
        span.SetStatus(codes.Ok, "")
    }
}
```

## ğŸ“ æ—¥å¿—èšåˆ

### 1. ç»“æ„åŒ–æ—¥å¿—é…ç½®

```go
package logging

import (
    "context"
    "os"
    "github.com/sirupsen/logrus"
    "go.opentelemetry.io/otel/trace"
)

// æ—¥å¿—é…ç½®
type LogConfig struct {
    Level      string `yaml:"level"`
    Format     string `yaml:"format"`  // json, text
    Output     string `yaml:"output"`  // stdout, file
    FilePath   string `yaml:"file_path"`
    MaxSize    int    `yaml:"max_size"`    // MB
    MaxBackups int    `yaml:"max_backups"`
    MaxAge     int    `yaml:"max_age"`     // days
}

// åˆå§‹åŒ–ç»“æ„åŒ–æ—¥å¿—
func InitLogger(config *LogConfig) *logrus.Logger {
    logger := logrus.New()
    
    // è®¾ç½®æ—¥å¿—çº§åˆ«
    level, err := logrus.ParseLevel(config.Level)
    if err != nil {
        level = logrus.InfoLevel
    }
    logger.SetLevel(level)
    
    // è®¾ç½®æ—¥å¿—æ ¼å¼
    if config.Format == "json" {
        logger.SetFormatter(&logrus.JSONFormatter{
            TimestampFormat: "2006-01-02 15:04:05.000",
            FieldMap: logrus.FieldMap{
                logrus.FieldKeyTime:  "timestamp",
                logrus.FieldKeyLevel: "level",
                logrus.FieldKeyMsg:   "message",
            },
        })
    } else {
        logger.SetFormatter(&logrus.TextFormatter{
            TimestampFormat: "2006-01-02 15:04:05.000",
            FullTimestamp:   true,
        })
    }
    
    // è®¾ç½®è¾“å‡º
    if config.Output == "file" {
        // ä½¿ç”¨æ–‡ä»¶è½®è½¬
        setupFileRotation(logger, config)
    } else {
        logger.SetOutput(os.Stdout)
    }
    
    return logger
}

// é“¾è·¯è¿½è¸ªæ—¥å¿—é’©å­
type TracingHook struct{}

func (hook *TracingHook) Levels() []logrus.Level {
    return logrus.AllLevels
}

func (hook *TracingHook) Fire(entry *logrus.Entry) error {
    if entry.Context != nil {
        span := trace.SpanFromContext(entry.Context)
        if span.SpanContext().IsValid() {
            entry.Data["trace_id"] = span.SpanContext().TraceID().String()
            entry.Data["span_id"] = span.SpanContext().SpanID().String()
        }
    }
    return nil
}

// ä¸šåŠ¡æ—¥å¿—åŒ…è£…å™¨
type BusinessLogger struct {
    logger *logrus.Logger
}

func NewBusinessLogger(logger *logrus.Logger) *BusinessLogger {
    logger.AddHook(&TracingHook{})
    return &BusinessLogger{logger: logger}
}

// ç”¨æˆ·æ“ä½œæ—¥å¿—
func (bl *BusinessLogger) LogUserAction(ctx context.Context, userID int64, action, details string) {
    bl.logger.WithContext(ctx).WithFields(logrus.Fields{
        "user_id": userID,
        "action":  action,
        "details": details,
        "type":    "user_action",
    }).Info("ç”¨æˆ·æ“ä½œ")
}

// ä¸šåŠ¡å¼‚å¸¸æ—¥å¿—
func (bl *BusinessLogger) LogBusinessError(ctx context.Context, err error, operation string, params map[string]interface{}) {
    fields := logrus.Fields{
        "error":     err.Error(),
        "operation": operation,
        "type":      "business_error",
    }
    
    for k, v := range params {
        fields[k] = v
    }
    
    bl.logger.WithContext(ctx).WithFields(fields).Error("ä¸šåŠ¡å¼‚å¸¸")
}

// æ€§èƒ½æ—¥å¿—
func (bl *BusinessLogger) LogPerformance(ctx context.Context, operation string, duration time.Duration, params map[string]interface{}) {
    fields := logrus.Fields{
        "operation": operation,
        "duration":  duration.Milliseconds(),
        "type":      "performance",
    }
    
    for k, v := range params {
        fields[k] = v
    }
    
    level := logrus.InfoLevel
    if duration > time.Second {
        level = logrus.WarnLevel
    }
    
    bl.logger.WithContext(ctx).WithFields(fields).Log(level, "æ€§èƒ½è®°å½•")
}
```

### 2. ELK Stacké›†æˆ

```yaml
# docker-compose.yml - ELK Stack
version: '3.8'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - es_data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    ports:
      - "5044:5044"
      - "9600:9600"
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    depends_on:
      - elasticsearch

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    volumes:
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/log/yyhertz:/var/log/yyhertz:ro
    depends_on:
      - logstash

volumes:
  es_data:
```

```yaml
# filebeat.yml
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /var/log/yyhertz/*.log
    fields:
      service: yyhertz
      environment: production
    fields_under_root: true
    json.keys_under_root: true
    json.add_error_key: true

output.logstash:
  hosts: ["logstash:5044"]

processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
```

## ğŸš¨ å‘Šè­¦é…ç½®

### 1. AlertManageré…ç½®

```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'smtp.company.com:587'
  smtp_from: 'alerts@company.com'
  smtp_auth_username: 'alerts@company.com'
  smtp_auth_password: 'password'

templates:
  - '/etc/alertmanager/templates/*.tmpl'

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'default'
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
    - match:
        severity: warning
      receiver: 'warning-alerts'

receivers:
  - name: 'default'
    webhook_configs:
      - url: 'http://webhook-service:8080/alerts'
        
  - name: 'critical-alerts'
    email_configs:
      - to: 'ops-team@company.com'
        subject: 'ğŸš¨ [CRITICAL] YYHertz Alert'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          {{ end }}
    webhook_configs:
      - url: 'http://dingtalk-webhook:8080/critical'
        
  - name: 'warning-alerts'
    email_configs:
      - to: 'dev-team@company.com'
        subject: 'âš ï¸ [WARNING] YYHertz Alert'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'cluster', 'service']
```

### 2. Prometheuså‘Šè­¦è§„åˆ™

```yaml
# alert-rules.yml
groups:
  - name: yyhertz-application
    rules:
      # HTTPé”™è¯¯ç‡å‘Šè­¦
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status_code=~"5.."}[5m])) by (service)
            /
            sum(rate(http_requests_total[5m])) by (service)
          ) > 0.05
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "é«˜é”™è¯¯ç‡å‘Šè­¦"
          description: "æœåŠ¡ {{ $labels.service }} 5åˆ†é’Ÿå†…é”™è¯¯ç‡è¶…è¿‡5%ï¼Œå½“å‰å€¼: {{ $value | humanizePercentage }}"

      - alert: CriticalErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status_code=~"5.."}[5m])) by (service)
            /
            sum(rate(http_requests_total[5m])) by (service)
          ) > 0.1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "ä¸¥é‡é”™è¯¯ç‡å‘Šè­¦"
          description: "æœåŠ¡ {{ $labels.service }} é”™è¯¯ç‡è¶…è¿‡10%ï¼Œå½“å‰å€¼: {{ $value | humanizePercentage }}"

      # å“åº”å»¶è¿Ÿå‘Šè­¦
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95, 
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
          ) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "é«˜å»¶è¿Ÿå‘Šè­¦"
          description: "æœåŠ¡ {{ $labels.service }} P95å»¶è¿Ÿè¶…è¿‡1ç§’ï¼Œå½“å‰å€¼: {{ $value }}s"

      # æ•°æ®åº“è¿æ¥æ•°å‘Šè­¦
      - alert: HighDBConnections
        expr: |
          db_connections_in_use / db_max_connections > 0.8
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "æ•°æ®åº“è¿æ¥æ•°è¿‡é«˜"
          description: "æ•°æ®åº“è¿æ¥ä½¿ç”¨ç‡è¶…è¿‡80%ï¼Œå½“å‰: {{ $value | humanizePercentage }}"

      # Redisè¿æ¥å‘Šè­¦
      - alert: RedisConnectionFailed
        expr: |
          redis_connected_clients == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redisè¿æ¥å¤±è´¥"
          description: "Redisè¿æ¥æ•°ä¸º0ï¼Œå¯èƒ½æœåŠ¡ä¸å¯ç”¨"

      # ä¸šåŠ¡æŒ‡æ ‡å‘Šè­¦
      - alert: UserLoginFailureSpike
        expr: |
          increase(user_login_total{status="failed"}[5m]) > 100
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "ç”¨æˆ·ç™»å½•å¤±è´¥æ¿€å¢"
          description: "5åˆ†é’Ÿå†…ç™»å½•å¤±è´¥æ¬¡æ•°è¶…è¿‡100æ¬¡ï¼Œå¯èƒ½å­˜åœ¨å¼‚å¸¸"

  - name: yyhertz-infrastructure
    rules:
      # ç³»ç»Ÿèµ„æºå‘Šè­¦
      - alert: HighCPUUsage
        expr: |
          100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "CPUä½¿ç”¨ç‡è¿‡é«˜"
          description: "å®ä¾‹ {{ $labels.instance }} CPUä½¿ç”¨ç‡è¶…è¿‡80%ï¼Œå½“å‰: {{ $value }}%"

      - alert: HighMemoryUsage
        expr: |
          (1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "å®ä¾‹ {{ $labels.instance }} å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡85%ï¼Œå½“å‰: {{ $value }}%"

      - alert: DiskSpaceLow
        expr: |
          (1 - node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 > 90
        for: 10m
        labels:
          severity: critical
        annotations:
          summary: "ç£ç›˜ç©ºé—´ä¸è¶³"
          description: "å®ä¾‹ {{ $labels.instance }} ç£ç›˜ {{ $labels.mountpoint }} ä½¿ç”¨ç‡è¶…è¿‡90%"
```

### 3. é’‰é’‰/ä¼ä¸šå¾®ä¿¡å‘Šè­¦é›†æˆ

```go
// å‘Šè­¦é€šçŸ¥æœåŠ¡
package alerting

import (
    "bytes"
    "encoding/json"
    "fmt"
    "net/http"
    "time"
)

// é’‰é’‰æœºå™¨äºº
type DingTalkBot struct {
    WebhookURL string
    Secret     string
}

type DingTalkMessage struct {
    MsgType  string                 `json:"msgtype"`
    Markdown *DingTalkMarkdown      `json:"markdown,omitempty"`
    At       *DingTalkAt           `json:"at,omitempty"`
}

type DingTalkMarkdown struct {
    Title string `json:"title"`
    Text  string `json:"text"`
}

type DingTalkAt struct {
    AtMobiles []string `json:"atMobiles"`
    IsAtAll   bool     `json:"isAtAll"`
}

func (dt *DingTalkBot) SendAlert(alert *Alert) error {
    message := &DingTalkMessage{
        MsgType: "markdown",
        Markdown: &DingTalkMarkdown{
            Title: fmt.Sprintf("ğŸš¨ %s", alert.AlertName),
            Text: fmt.Sprintf(`
### %s å‘Šè­¦é€šçŸ¥

**å‘Šè­¦çº§åˆ«**: %s
**æœåŠ¡åç§°**: %s
**å‘Šè­¦æ—¶é—´**: %s
**å‘Šè­¦æè¿°**: %s

**è¯¦ç»†ä¿¡æ¯**:
- Instance: %s
- Value: %s

[æŸ¥çœ‹è¯¦æƒ…](%s)
            `,
                alert.AlertName,
                alert.Severity,
                alert.Service,
                alert.StartsAt.Format("2006-01-02 15:04:05"),
                alert.Description,
                alert.Instance,
                alert.Value,
                alert.GeneratorURL,
            ),
        },
    }
    
    if alert.Severity == "critical" {
        message.At = &DingTalkAt{IsAtAll: true}
    }
    
    return dt.sendMessage(message)
}

func (dt *DingTalkBot) sendMessage(message *DingTalkMessage) error {
    jsonData, err := json.Marshal(message)
    if err != nil {
        return err
    }
    
    resp, err := http.Post(dt.WebhookURL, "application/json", bytes.NewBuffer(jsonData))
    if err != nil {
        return err
    }
    defer resp.Body.Close()
    
    if resp.StatusCode != http.StatusOK {
        return fmt.Errorf("é’‰é’‰æ¶ˆæ¯å‘é€å¤±è´¥ï¼ŒçŠ¶æ€ç : %d", resp.StatusCode)
    }
    
    return nil
}

// å‘Šè­¦ç®¡ç†å™¨
type AlertManager struct {
    dingTalk     *DingTalkBot
    wechat       *WeChatBot
    emailSender  *EmailSender
    alertHistory map[string]*Alert
}

func NewAlertManager() *AlertManager {
    return &AlertManager{
        dingTalk:     &DingTalkBot{WebhookURL: os.Getenv("DINGTALK_WEBHOOK")},
        wechat:       &WeChatBot{WebhookURL: os.Getenv("WECHAT_WEBHOOK")},
        emailSender:  NewEmailSender(),
        alertHistory: make(map[string]*Alert),
    }
}

func (am *AlertManager) HandleAlert(alert *Alert) error {
    // æ£€æŸ¥å‘Šè­¦æŠ‘åˆ¶
    if am.shouldSuppress(alert) {
        return nil
    }
    
    // è®°å½•å‘Šè­¦å†å²
    am.alertHistory[alert.Fingerprint] = alert
    
    // æ ¹æ®ä¸¥é‡ç¨‹åº¦é€‰æ‹©é€šçŸ¥æ¸ é“
    switch alert.Severity {
    case "critical":
        // ä¸¥é‡å‘Šè­¦ï¼šé’‰é’‰ + ä¼ä¸šå¾®ä¿¡ + é‚®ä»¶ + çŸ­ä¿¡
        go am.dingTalk.SendAlert(alert)
        go am.wechat.SendAlert(alert)
        go am.emailSender.SendAlert(alert)
        go am.sendSMS(alert)
        
    case "warning":
        // è­¦å‘Šå‘Šè­¦ï¼šé’‰é’‰ + é‚®ä»¶
        go am.dingTalk.SendAlert(alert)
        go am.emailSender.SendAlert(alert)
        
    default:
        // ä¿¡æ¯å‘Šè­¦ï¼šä»…é’‰é’‰
        go am.dingTalk.SendAlert(alert)
    }
    
    return nil
}

// å‘Šè­¦æŠ‘åˆ¶é€»è¾‘
func (am *AlertManager) shouldSuppress(alert *Alert) bool {
    key := alert.Fingerprint
    
    // æ£€æŸ¥æ˜¯å¦åœ¨æŠ‘åˆ¶æ—¶é—´å†…
    if lastAlert, exists := am.alertHistory[key]; exists {
        if time.Since(lastAlert.StartsAt) < 15*time.Minute {
            return true // 15åˆ†é’Ÿå†…ç›¸åŒå‘Šè­¦ï¼ŒæŠ‘åˆ¶
        }
    }
    
    return false
}
```

## ğŸ“Š Grafanaä»ªè¡¨æ¿

### 1. YYHertzåº”ç”¨ç›‘æ§ä»ªè¡¨æ¿

```json
{
  "dashboard": {
    "title": "YYHertzåº”ç”¨ç›‘æ§",
    "tags": ["yyhertz", "application"],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "panels": [
      {
        "title": "è¯·æ±‚é‡ (RPS)",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
        "targets": [
          {
            "expr": "sum(rate(http_requests_total[1m])) by (service)",
            "legendFormat": "{{service}}"
          }
        ],
        "yAxes": [
          {"label": "Requests/sec", "min": 0}
        ]
      },
      {
        "title": "é”™è¯¯ç‡",
        "type": "graph", 
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{status_code=~\"5..\"}[1m])) by (service) / sum(rate(http_requests_total[1m])) by (service)",
            "legendFormat": "{{service}} é”™è¯¯ç‡"
          }
        ],
        "yAxes": [
          {"label": "Error Rate", "max": 1, "min": 0}
        ],
        "alert": {
          "conditions": [
            {
              "query": {"params": ["A", "1m", "now"]},
              "reducer": {"params": [], "type": "last"},
              "evaluator": {"params": [0.05], "type": "gt"}
            }
          ],
          "executionErrorState": "alerting",
          "frequency": "10s",
          "handler": 1,
          "name": "é«˜é”™è¯¯ç‡å‘Šè­¦",
          "noDataState": "no_data"
        }
      },
      {
        "title": "å“åº”æ—¶é—´åˆ†å¸ƒ",
        "type": "heatmap",
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8},
        "targets": [
          {
            "expr": "increase(http_request_duration_seconds_bucket[1m])",
            "legendFormat": "{{le}}"
          }
        ]
      },
      {
        "title": "æ•°æ®åº“æ€§èƒ½",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16},
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(db_query_duration_seconds_bucket[1m])) by (le))",
            "legendFormat": "DB P95å»¶è¿Ÿ"
          },
          {
            "expr": "sum(rate(db_query_total[1m]))",
            "legendFormat": "DB QPS"
          }
        ]
      },
      {
        "title": "Redisæ€§èƒ½",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16},
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(redis_operation_duration_seconds_bucket[1m])) by (le))",
            "legendFormat": "Redis P95å»¶è¿Ÿ"
          }
        ]
      }
    ]
  }
}
```

### 2. ä¸šåŠ¡ç›‘æ§ä»ªè¡¨æ¿

```json
{
  "dashboard": {
    "title": "YYHertzä¸šåŠ¡ç›‘æ§",
    "panels": [
      {
        "title": "ç”¨æˆ·æ´»è·ƒåº¦",
        "type": "stat",
        "targets": [
          {
            "expr": "active_users",
            "legendFormat": "åœ¨çº¿ç”¨æˆ·"
          }
        ]
      },
      {
        "title": "ç™»å½•æˆåŠŸç‡",
        "type": "gauge",
        "targets": [
          {
            "expr": "sum(rate(user_login_total{status=\"success\"}[5m])) / sum(rate(user_login_total[5m]))",
            "legendFormat": "æˆåŠŸç‡"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "min": 0,
            "max": 1,
            "thresholds": {
              "steps": [
                {"color": "red", "value": 0},
                {"color": "yellow", "value": 0.8},
                {"color": "green", "value": 0.95}
              ]
            }
          }
        }
      }
    ]
  }
}
```

## ğŸ”— ç›¸å…³èµ„æº

- **[MyBatisæ€§èƒ½ä¼˜åŒ–](./mybatis-performance)** - æ•°æ®è®¿é—®å±‚ç›‘æ§é›†æˆ
- **[æ•°æ®åº“è°ƒä¼˜](./database-tuning)** - æ•°æ®åº“ç›‘æ§æŒ‡æ ‡
- **[ç¼“å­˜ç­–ç•¥](./caching-strategies)** - ç¼“å­˜ç³»ç»Ÿç›‘æ§

---

**å®Œæ•´çš„ç›‘æ§å‘Šè­¦ä½“ç³»æ˜¯é«˜å¯ç”¨ç³»ç»Ÿçš„åŸºçŸ³** - é€šè¿‡æŒ‡æ ‡æ”¶é›†ã€é“¾è·¯è¿½è¸ªã€æ—¥å¿—èšåˆå’Œæ™ºèƒ½å‘Šè­¦ï¼Œå®ç°ç³»ç»Ÿçš„å…¨é¢å¯è§‚æµ‹æ€§ï¼ğŸš€
# æ•°æ®åº“è°ƒä¼˜

YYHertzæ¡†æ¶ä¸‹çš„æ•°æ®åº“æ€§èƒ½è°ƒä¼˜æŒ‡å—ï¼Œæ¶µç›–MySQL/PostgreSQLçš„é…ç½®ä¼˜åŒ–ã€ç´¢å¼•è®¾è®¡ã€æŸ¥è¯¢ä¼˜åŒ–ç­‰å…³é”®æŠ€æœ¯ã€‚

## ğŸ¯ è°ƒä¼˜ç›®æ ‡

### æ€§èƒ½æŒ‡æ ‡åŸºå‡†

| æŒ‡æ ‡ç±»å‹ | MySQLç›®æ ‡å€¼ | PostgreSQLç›®æ ‡å€¼ | è¯´æ˜ |
|----------|-------------|------------------|------|
| **å“åº”å»¶è¿Ÿ** | P95 < 50ms | P95 < 50ms | 95%æŸ¥è¯¢åœ¨50mså†…å®Œæˆ |
| **ååé‡** | >5000 QPS | >4000 QPS | æ¯ç§’æŸ¥è¯¢å¤„ç†èƒ½åŠ› |
| **è¿æ¥æ•°** | 200-500 | 100-300 | åŒæ—¶è¿æ¥æ•°èŒƒå›´ |
| **CPUä½¿ç”¨ç‡** | < 80% | < 80% | å³°å€¼æ—¶æœŸCPUå ç”¨ |
| **å†…å­˜ä½¿ç”¨ç‡** | < 85% | < 85% | ç¼“å†²æ± å†…å­˜å ç”¨ |

### è°ƒä¼˜ä¼˜å…ˆçº§

```mermaid
graph TD
    A[æ•°æ®åº“è°ƒä¼˜] --> B[é…ç½®ä¼˜åŒ–]
    A --> C[ç´¢å¼•ä¼˜åŒ–] 
    A --> D[æŸ¥è¯¢ä¼˜åŒ–]
    A --> E[æ¶æ„ä¼˜åŒ–]
    
    B --> B1[å†…å­˜é…ç½®]
    B --> B2[è¿æ¥é…ç½®]
    B --> B3[æ—¥å¿—é…ç½®]
    
    C --> C1[ä¸»é”®ç´¢å¼•]
    C --> C2[å¤åˆç´¢å¼•]
    C --> C3[è¦†ç›–ç´¢å¼•]
    
    D --> D1[SQLé‡å†™]
    D --> D2[æ‰§è¡Œè®¡åˆ’]
    D --> D3[æ‰¹é‡æ“ä½œ]
    
    E --> E1[è¯»å†™åˆ†ç¦»]
    E --> E2[åˆ†åº“åˆ†è¡¨]
    E --> E3[ç¼“å­˜æ¶æ„]
```

## ğŸ”§ MySQLè°ƒä¼˜

### 1. é…ç½®æ–‡ä»¶ä¼˜åŒ–

#### åŸºç¡€é…ç½® (`my.cnf`)

```ini
[mysql]
default-character-set = utf8mb4

[mysqld]
# === åŸºç¡€è®¾ç½® ===
port = 3306
server-id = 1
character-set-server = utf8mb4
collation-server = utf8mb4_unicode_ci

# === å†…å­˜é…ç½® ===
# InnoDBç¼“å†²æ± å¤§å°ï¼ˆæ¨èä¸ºç‰©ç†å†…å­˜çš„70-80%ï¼‰
innodb_buffer_pool_size = 4G
innodb_buffer_pool_instances = 4

# æŸ¥è¯¢ç¼“å­˜ï¼ˆMySQL 8.0å·²ç§»é™¤ï¼‰
query_cache_type = OFF
query_cache_size = 0

# æ’åºç¼“å†²åŒº
sort_buffer_size = 2M
read_buffer_size = 1M
read_rnd_buffer_size = 4M
join_buffer_size = 2M

# === è¿æ¥é…ç½® ===
max_connections = 500
max_connect_errors = 100
connect_timeout = 10
wait_timeout = 300
interactive_timeout = 300

# === InnoDBé…ç½® ===
innodb_file_per_table = ON
innodb_flush_log_at_trx_commit = 1
innodb_log_file_size = 256M
innodb_log_files_in_group = 3
innodb_io_capacity = 200
innodb_io_capacity_max = 2000

# === æ…¢æŸ¥è¯¢æ—¥å¿— ===
slow_query_log = ON
slow_query_log_file = /var/log/mysql/mysql-slow.log
long_query_time = 0.5
log_queries_not_using_indexes = ON
```

#### é«˜æ€§èƒ½é…ç½® (`production.cnf`)

```ini
[mysqld]
# === é«˜æ€§èƒ½è®¾ç½® ===
# è·³è¿‡åç§°è§£æ
skip_name_resolve = ON

# ç¦ç”¨DNSæŸ¥æ‰¾
skip_host_cache = ON

# äºŒè¿›åˆ¶æ—¥å¿—
log-bin = mysql-bin
binlog_format = ROW
expire_logs_days = 7
max_binlog_size = 1G

# === é«˜çº§InnoDBè®¾ç½® ===
# åˆ·æ–°ç­–ç•¥
innodb_flush_method = O_DIRECT
innodb_doublewrite = ON

# å¹¶å‘æ§åˆ¶
innodb_thread_concurrency = 0
innodb_read_io_threads = 4
innodb_write_io_threads = 4

# é”ç­‰å¾…è¶…æ—¶
innodb_lock_wait_timeout = 50

# === æ€§èƒ½æ¨¡å¼ ===
performance_schema = ON
performance_schema_max_table_instances = 12500
```

### 2. ç´¢å¼•è®¾è®¡ä¸ä¼˜åŒ–

#### ç´¢å¼•è®¾è®¡åŸåˆ™

```sql
-- âœ… å¥½çš„ç´¢å¼•è®¾è®¡
CREATE TABLE users (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    email VARCHAR(255) NOT NULL,
    status TINYINT NOT NULL DEFAULT 1,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    
    -- å•åˆ—ç´¢å¼•
    INDEX idx_email (email),
    INDEX idx_status (status),
    INDEX idx_created_at (created_at),
    
    -- å¤åˆç´¢å¼•ï¼ˆé‡è¦ï¼šé¡ºåºå¾ˆå…³é”®ï¼‰
    INDEX idx_status_created (status, created_at),
    INDEX idx_email_status (email, status),
    
    -- å”¯ä¸€ç´¢å¼•
    UNIQUE KEY uk_email (email)
);

-- âŒ é¿å…çš„ç´¢å¼•è®¾è®¡
-- è¿‡å¤šçš„å•åˆ—ç´¢å¼•ä¼šå½±å“å†™å…¥æ€§èƒ½
-- é‡å¤æˆ–å†—ä½™çš„ç´¢å¼•
-- åœ¨å°è¡¨ä¸Šå»ºç«‹è¿‡å¤šç´¢å¼•
```

#### ç´¢å¼•ä¼˜åŒ–ç­–ç•¥

```sql
-- 1. è¦†ç›–ç´¢å¼•ä¼˜åŒ–
-- åŸæŸ¥è¯¢éœ€è¦å›è¡¨
SELECT id, name, email FROM users WHERE status = 1 ORDER BY created_at;

-- åˆ›å»ºè¦†ç›–ç´¢å¼•é¿å…å›è¡¨
CREATE INDEX idx_status_created_cover (status, created_at, id, name, email);

-- 2. å‰ç¼€ç´¢å¼•ä¼˜åŒ–
-- å¯¹äºé•¿å­—ç¬¦ä¸²å­—æ®µï¼Œä½¿ç”¨å‰ç¼€ç´¢å¼•
CREATE INDEX idx_description_prefix (description(50));

-- 3. æ¡ä»¶ç´¢å¼•ï¼ˆMySQL 8.0+ï¼‰
CREATE INDEX idx_active_users (created_at) WHERE status = 1;

-- 4. ç´¢å¼•æç¤ºä¼˜åŒ–
SELECT /*+ USE INDEX(idx_status_created) */ * 
FROM users 
WHERE status = 1 AND created_at > '2024-01-01';
```

### 3. SQLæŸ¥è¯¢ä¼˜åŒ–

#### æŸ¥è¯¢é‡å†™æŠ€å·§

```sql
-- âŒ ä½æ•ˆæŸ¥è¯¢
SELECT * FROM users WHERE YEAR(created_at) = 2024;
SELECT * FROM users WHERE name LIKE '%john%';
SELECT * FROM orders WHERE user_id IN (SELECT id FROM users WHERE status = 1);

-- âœ… ä¼˜åŒ–åæŸ¥è¯¢
-- é¿å…å‡½æ•°æ“ä½œï¼Œä½¿ç”¨èŒƒå›´æŸ¥è¯¢
SELECT * FROM users 
WHERE created_at >= '2024-01-01' AND created_at < '2025-01-01';

-- å‰ç¼€åŒ¹é…ï¼Œå¯ä»¥ä½¿ç”¨ç´¢å¼•
SELECT * FROM users WHERE name LIKE 'john%';

-- ä½¿ç”¨JOINæ›¿ä»£å­æŸ¥è¯¢
SELECT o.* FROM orders o 
INNER JOIN users u ON o.user_id = u.id 
WHERE u.status = 1;
```

#### æ‰¹é‡æ“ä½œä¼˜åŒ–

```go
// YYHertzæ¡†æ¶ä¸­çš„æ‰¹é‡ä¼˜åŒ–ç¤ºä¾‹
func (c *UserController) PostBatchCreate() {
    ctx := context.Background()
    
    var users []User
    if err := c.ShouldBindJSON(&users); err != nil {
        c.Error(400, "å‚æ•°é”™è¯¯")
        return
    }
    
    // æ‰¹é‡æ’å…¥ä¼˜åŒ–
    batchSize := 1000
    for i := 0; i < len(users); i += batchSize {
        end := i + batchSize
        if end > len(users) {
            end = len(users)
        }
        
        batch := users[i:end]
        
        // ä½¿ç”¨äº‹åŠ¡æ‰¹é‡æ’å…¥
        err := c.db.Transaction(func(tx *gorm.DB) error {
            return tx.CreateInBatches(batch, batchSize).Error
        })
        
        if err != nil {
            c.Error(500, "æ‰¹é‡æ’å…¥å¤±è´¥")
            return
        }
    }
    
    c.JSON(mvc.Result{Success: true, Data: len(users)})
}
```

## ğŸ˜ PostgreSQLè°ƒä¼˜

### 1. é…ç½®ä¼˜åŒ–

#### `postgresql.conf` åŸºç¡€é…ç½®

```ini
# === å†…å­˜é…ç½® ===
shared_buffers = 1GB                    # æ¨èä¸ºç‰©ç†å†…å­˜çš„25%
effective_cache_size = 3GB              # æ¨èä¸ºç‰©ç†å†…å­˜çš„75%
work_mem = 4MB                          # æ’åº/å“ˆå¸Œæ“ä½œå†…å­˜
maintenance_work_mem = 256MB            # ç»´æŠ¤æ“ä½œå†…å­˜

# === æ£€æŸ¥ç‚¹é…ç½® ===
checkpoint_completion_target = 0.7      # æ£€æŸ¥ç‚¹å®Œæˆæ—¶é—´
wal_buffers = 16MB                      # WALç¼“å†²åŒº
max_wal_size = 2GB                      # æœ€å¤§WALå¤§å°
min_wal_size = 512MB                    # æœ€å°WALå¤§å°

# === è¿æ¥é…ç½® ===
max_connections = 200                    # æœ€å¤§è¿æ¥æ•°
shared_preload_libraries = 'pg_stat_statements'

# === æŸ¥è¯¢è®¡åˆ’ ===
random_page_cost = 1.1                  # SSDå­˜å‚¨å»ºè®®å€¼
effective_io_concurrency = 200          # SSDå¹¶å‘IO

# === æ—¥å¿—é…ç½® ===
logging_collector = on
log_directory = 'pg_log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_min_duration_statement = 1000       # è®°å½•è¶…è¿‡1ç§’çš„æŸ¥è¯¢
log_statement = 'mod'                   # è®°å½•ä¿®æ”¹è¯­å¥
```

### 2. ç´¢å¼•ç­–ç•¥

#### PostgreSQLç‰¹æœ‰ç´¢å¼•ç±»å‹

```sql
-- B-treeç´¢å¼•ï¼ˆé»˜è®¤ï¼‰
CREATE INDEX idx_users_email ON users(email);

-- éƒ¨åˆ†ç´¢å¼•
CREATE INDEX idx_active_users ON users(created_at) WHERE status = 'active';

-- è¡¨è¾¾å¼ç´¢å¼•
CREATE INDEX idx_users_lower_name ON users(lower(name));

-- GINç´¢å¼•ï¼ˆé€‚åˆæ•°ç»„ã€JSONã€å…¨æ–‡æœç´¢ï¼‰
CREATE INDEX idx_users_tags ON users USING gin(tags);

-- GiSTç´¢å¼•ï¼ˆé€‚åˆå‡ ä½•æ•°æ®ã€èŒƒå›´ç±»å‹ï¼‰
CREATE INDEX idx_users_location ON users USING gist(location);

-- å¤åˆç´¢å¼•ï¼ˆæ³¨æ„åˆ—é¡ºåºï¼‰
CREATE INDEX idx_users_status_created ON users(status, created_at);
```

### 3. æŸ¥è¯¢ä¼˜åŒ–

#### EXPLAINåˆ†æ

```sql
-- åŸºç¡€æ‰§è¡Œè®¡åˆ’
EXPLAIN SELECT * FROM users WHERE status = 'active';

-- è¯¦ç»†åˆ†æï¼ˆåŒ…å«å®é™…æ‰§è¡Œæ—¶é—´ï¼‰
EXPLAIN (ANALYZE, BUFFERS, VERBOSE) 
SELECT u.name, COUNT(o.id) as order_count
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
WHERE u.status = 'active'
GROUP BY u.id, u.name
ORDER BY order_count DESC;
```

## ğŸ“Š YYHertzæ¡†æ¶ä¸­çš„æ•°æ®åº“ç›‘æ§

### 1. æ€§èƒ½ç›‘æ§é›†æˆ

```go
package monitoring

import (
    "context"
    "time"
    "github.com/prometheus/client_golang/prometheus"
    "gorm.io/gorm"
)

// æ•°æ®åº“æ€§èƒ½æŒ‡æ ‡
var (
    dbQueryDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "db_query_duration_seconds",
            Help: "Database query duration",
            Buckets: []float64{0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0},
        },
        []string{"operation", "table"},
    )
    
    dbQueryTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "db_queries_total",
            Help: "Total database queries",
        },
        []string{"operation", "table", "status"},
    )
)

// GORMæ’ä»¶ï¼šç›‘æ§æ•°æ®åº“æŸ¥è¯¢
func NewMonitoringPlugin() gorm.Plugin {
    return &monitoringPlugin{}
}

type monitoringPlugin struct{}

func (p *monitoringPlugin) Name() string {
    return "monitoring"
}

func (p *monitoringPlugin) Initialize(db *gorm.DB) error {
    // æ³¨å†Œå›è°ƒ
    db.Callback().Query().Before("gorm:query").Register("monitoring:before_query", beforeQuery)
    db.Callback().Query().After("gorm:after_query").Register("monitoring:after_query", afterQuery)
    
    return nil
}

func beforeQuery(db *gorm.DB) {
    db.Set("monitoring:start_time", time.Now())
}

func afterQuery(db *gorm.DB) {
    startTime, exists := db.Get("monitoring:start_time")
    if !exists {
        return
    }
    
    duration := time.Since(startTime.(time.Time))
    
    // è®°å½•æŒ‡æ ‡
    operation := "select"
    table := db.Statement.Table
    status := "success"
    
    if db.Error != nil {
        status = "error"
    }
    
    dbQueryDuration.WithLabelValues(operation, table).Observe(duration.Seconds())
    dbQueryTotal.WithLabelValues(operation, table, status).Inc()
}
```

### 2. æ…¢æŸ¥è¯¢ç›‘æ§

```go
// æ…¢æŸ¥è¯¢ç›‘æ§ä¸­é—´ä»¶
func SlowQueryMiddleware(threshold time.Duration) gorm.Plugin {
    return &slowQueryPlugin{threshold: threshold}
}

type slowQueryPlugin struct {
    threshold time.Duration
}

func (p *slowQueryPlugin) Name() string {
    return "slow_query"
}

func (p *slowQueryPlugin) Initialize(db *gorm.DB) error {
    db.Callback().Query().After("gorm:query").Register("slow_query:after", func(db *gorm.DB) {
        elapsed := db.Statement.Context.Value("query_start_time")
        if elapsed == nil {
            return
        }
        
        duration := time.Since(elapsed.(time.Time))
        if duration > p.threshold {
            logrus.WithFields(logrus.Fields{
                "sql":      db.Statement.SQL.String(),
                "args":     db.Statement.Vars,
                "duration": duration.String(),
                "table":    db.Statement.Table,
            }).Warn("æ…¢æŸ¥è¯¢æ£€æµ‹")
        }
    })
    
    return nil
}
```

## ğŸ”§ æ¶æ„å±‚é¢ä¼˜åŒ–

### 1. è¯»å†™åˆ†ç¦»é…ç½®

```go
// è¯»å†™åˆ†ç¦»é…ç½®
type DatabaseConfig struct {
    Master DatabaseConnection `yaml:"master"`
    Slaves []DatabaseConnection `yaml:"slaves"`
}

type DatabaseConnection struct {
    Host     string `yaml:"host"`
    Port     int    `yaml:"port"`
    Database string `yaml:"database"`
    Username string `yaml:"username"`
    Password string `yaml:"password"`
    MaxOpenConns int `yaml:"max_open_conns"`
    MaxIdleConns int `yaml:"max_idle_conns"`
}

// ä½¿ç”¨è¯»å†™åˆ†ç¦»
func SetupReadWriteDB(config DatabaseConfig) (*gorm.DB, error) {
    // ä¸»åº“é…ç½®
    masterDSN := fmt.Sprintf("%s:%s@tcp(%s:%d)/%s?charset=utf8mb4&parseTime=True&loc=Local",
        config.Master.Username, config.Master.Password,
        config.Master.Host, config.Master.Port, config.Master.Database)
    
    masterDB, err := gorm.Open(mysql.Open(masterDSN), &gorm.Config{})
    if err != nil {
        return nil, err
    }
    
    // ä»åº“é…ç½®
    var slaveDSNs []gorm.Dialector
    for _, slave := range config.Slaves {
        dsn := fmt.Sprintf("%s:%s@tcp(%s:%d)/%s?charset=utf8mb4&parseTime=True&loc=Local",
            slave.Username, slave.Password,
            slave.Host, slave.Port, slave.Database)
        slaveDSNs = append(slaveDSNs, mysql.Open(dsn))
    }
    
    // ä½¿ç”¨DBResolveræ’ä»¶å®ç°è¯»å†™åˆ†ç¦»
    err = masterDB.Use(dbresolver.Register(dbresolver.Config{
        Replicas: slaveDSNs,
        Policy: dbresolver.RandomPolicy{}, // éšæœºé€‰æ‹©ä»åº“
    }))
    
    return masterDB, err
}
```

### 2. è¿æ¥æ± ä¼˜åŒ–

```yaml
# conf/database.yaml
master:
  host: "master.mysql.internal"
  port: 3306
  database: "yyhertz_prod"
  username: "app_user"
  password: "${DB_PASSWORD}"
  
  # è¿æ¥æ± ä¼˜åŒ–é…ç½®
  max_open_conns: 100              # æœ€å¤§æ‰“å¼€è¿æ¥æ•°
  max_idle_conns: 50               # æœ€å¤§ç©ºé—²è¿æ¥æ•°  
  conn_max_lifetime: "1h"          # è¿æ¥æœ€å¤§ç”Ÿå­˜æ—¶é—´
  conn_max_idle_time: "30m"        # è¿æ¥æœ€å¤§ç©ºé—²æ—¶é—´
  
  # è¶…æ—¶é…ç½®
  dial_timeout: "5s"               # è¿æ¥è¶…æ—¶
  read_timeout: "30s"              # è¯»å–è¶…æ—¶
  write_timeout: "30s"             # å†™å…¥è¶…æ—¶

slaves:
  - host: "slave1.mysql.internal"
    port: 3306
    max_open_conns: 50
    max_idle_conns: 25
  - host: "slave2.mysql.internal"
    port: 3306
    max_open_conns: 50
    max_idle_conns: 25
```

## ğŸ“ˆ æ€§èƒ½æµ‹è¯•ä¸åŸºå‡†

### 1. æ•°æ®åº“å‹åŠ›æµ‹è¯•

```bash
# ä½¿ç”¨sysbenchè¿›è¡ŒMySQLå‹åŠ›æµ‹è¯•
# å®‰è£…sysbench
sudo apt install sysbench

# å‡†å¤‡æµ‹è¯•æ•°æ®
sysbench oltp_read_write \
    --mysql-host=localhost \
    --mysql-port=3306 \
    --mysql-user=test \
    --mysql-password=test \
    --mysql-db=testdb \
    --tables=10 \
    --table-size=100000 \
    prepare

# è¿è¡Œæµ‹è¯•
sysbench oltp_read_write \
    --mysql-host=localhost \
    --mysql-port=3306 \
    --mysql-user=test \
    --mysql-password=test \
    --mysql-db=testdb \
    --tables=10 \
    --table-size=100000 \
    --threads=64 \
    --time=300 \
    --report-interval=10 \
    run
```

### 2. Goåº”ç”¨å±‚å‹åŠ›æµ‹è¯•

```go
// æ•°æ®åº“æ€§èƒ½æµ‹è¯•
func BenchmarkDatabaseOperations(b *testing.B) {
    db := setupTestDB()
    
    b.Run("SelectUser", func(b *testing.B) {
        b.ResetTimer()
        for i := 0; i < b.N; i++ {
            var user User
            db.First(&user, 1)
        }
    })
    
    b.Run("SelectUserList", func(b *testing.B) {
        b.ResetTimer()
        for i := 0; i < b.N; i++ {
            var users []User
            db.Limit(10).Find(&users)
        }
    })
    
    b.Run("CreateUser", func(b *testing.B) {
        b.ResetTimer()
        for i := 0; i < b.N; i++ {
            user := User{
                Name:  fmt.Sprintf("test_user_%d", i),
                Email: fmt.Sprintf("test_%d@example.com", i),
            }
            db.Create(&user)
        }
    })
}
```

## ğŸš¨ å‘Šè­¦ä¸ç›‘æ§

### 1. å…³é”®æŒ‡æ ‡å‘Šè­¦è§„åˆ™

```yaml
# Prometheuså‘Šè­¦è§„åˆ™
groups:
  - name: database
    rules:
      # æ•°æ®åº“è¿æ¥æ•°å‘Šè­¦
      - alert: DatabaseHighConnections
        expr: mysql_global_status_threads_connected / mysql_global_variables_max_connections > 0.8
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "æ•°æ®åº“è¿æ¥æ•°è¿‡é«˜"
          description: "æ•°æ®åº“è¿æ¥ä½¿ç”¨ç‡è¶…è¿‡80%ï¼Œå½“å‰: {{ $value }}%"
      
      # æ…¢æŸ¥è¯¢å‘Šè­¦
      - alert: DatabaseSlowQueries
        expr: increase(mysql_global_status_slow_queries[5m]) > 10
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "æ…¢æŸ¥è¯¢æ•°é‡å¼‚å¸¸"
          description: "5åˆ†é’Ÿå†…æ…¢æŸ¥è¯¢è¶…è¿‡10ä¸ª"
      
      # æ•°æ®åº“å¯ç”¨æ€§å‘Šè­¦
      - alert: DatabaseDown
        expr: mysql_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "æ•°æ®åº“ä¸å¯ç”¨"
          description: "MySQLæ•°æ®åº“è¿æ¥å¤±è´¥"
```

### 2. ç›‘æ§é¢æ¿é…ç½®

```json
{
  "dashboard": {
    "title": "æ•°æ®åº“æ€§èƒ½ç›‘æ§",
    "panels": [
      {
        "title": "QPS (Queries Per Second)",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(mysql_global_status_questions[5m])",
            "legendFormat": "QPS"
          }
        ]
      },
      {
        "title": "è¿æ¥æ•°ä½¿ç”¨æƒ…å†µ",
        "type": "graph",
        "targets": [
          {
            "expr": "mysql_global_status_threads_connected",
            "legendFormat": "æ´»è·ƒè¿æ¥"
          },
          {
            "expr": "mysql_global_variables_max_connections",
            "legendFormat": "æœ€å¤§è¿æ¥æ•°"
          }
        ]
      },
      {
        "title": "æŸ¥è¯¢å»¶è¿Ÿåˆ†å¸ƒ",
        "type": "heatmap",
        "targets": [
          {
            "expr": "increase(db_query_duration_seconds_bucket[5m])",
            "legendFormat": "{{le}}"
          }
        ]
      }
    ]
  }
}
```

## ğŸ“š ç›¸å…³èµ„æº

- **[MyBatisæ€§èƒ½ä¼˜åŒ–](./mybatis-performance.md)** - åº”ç”¨å±‚æ•°æ®è®¿é—®ä¼˜åŒ–
- **[ç¼“å­˜ç­–ç•¥](./caching-strategies.md)** - Redisç¼“å­˜è®¾è®¡æœ€ä½³å®è·µ
- **[ç›‘æ§å‘Šè­¦](./monitoring-alerting.md)** - å®Œæ•´çš„ç›‘æ§å‘Šè­¦è§£å†³æ–¹æ¡ˆ

---

**æ•°æ®åº“è°ƒä¼˜æ˜¯ç³»ç»Ÿæ€§å·¥ç¨‹** - éœ€è¦ä»é…ç½®ã€ç´¢å¼•ã€æŸ¥è¯¢ã€æ¶æ„ç­‰å¤šä¸ªç»´åº¦ç»¼åˆä¼˜åŒ–ï¼ŒæŒç»­ç›‘æ§å’Œè°ƒæ•´ï¼ğŸš€
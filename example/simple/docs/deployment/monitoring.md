# ğŸ“Š ç›‘æ§å‘Šè­¦

YYHertzåº”ç”¨çš„å…¨é¢ç›‘æ§å’Œå‘Šè­¦ä½“ç³»æ­å»ºã€‚

## Prometheusç›‘æ§

### æŒ‡æ ‡æ”¶é›†

```go
package middleware

import (
    "time"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    httpRequestsTotal = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "yyhertz_http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "endpoint", "status"},
    )

    httpRequestDuration = promauto.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "yyhertz_http_request_duration_seconds",
            Help: "Duration of HTTP requests",
            Buckets: prometheus.DefBuckets,
        },
        []string{"method", "endpoint"},
    )

    dbConnectionsActive = promauto.NewGauge(prometheus.GaugeOpts{
        Name: "yyhertz_db_connections_active",
        Help: "Number of active database connections",
    })
)

func PrometheusMiddleware() gin.HandlerFunc {
    return gin.HandlerFunc(func(c *gin.Context) {
        start := time.Now()
        
        c.Next()
        
        duration := time.Since(start).Seconds()
        status := strconv.Itoa(c.Writer.Status())
        
        httpRequestsTotal.WithLabelValues(c.Request.Method, c.FullPath(), status).Inc()
        httpRequestDuration.WithLabelValues(c.Request.Method, c.FullPath()).Observe(duration)
    })
}
```

### Prometheusé…ç½®

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'yyhertz'
    static_configs:
      - targets: ['yyhertz:8080']
    metrics_path: '/metrics'
    scrape_interval: 10s
```

## Grafanaä»ªè¡¨æ¿

### å…³é”®æŒ‡æ ‡ä»ªè¡¨æ¿

1. **åº”ç”¨æ€§èƒ½æŒ‡æ ‡**
   - HTTPè¯·æ±‚ç‡ (RPS)
   - å“åº”æ—¶é—´åˆ†å¸ƒ
   - é”™è¯¯ç‡ç»Ÿè®¡
   - å¹¶å‘è¿æ¥æ•°

2. **ç³»ç»Ÿèµ„æºæŒ‡æ ‡**
   - CPUä½¿ç”¨ç‡
   - å†…å­˜ä½¿ç”¨ç‡
   - ç£ç›˜I/O
   - ç½‘ç»œæµé‡

3. **ä¸šåŠ¡æŒ‡æ ‡**
   - ç”¨æˆ·æ³¨å†Œæ•°
   - æ´»è·ƒç”¨æˆ·æ•°
   - è®¢å•å¤„ç†é‡
   - æ”¶å…¥ç»Ÿè®¡

### ä»ªè¡¨æ¿JSONé…ç½®

```json
{
  "dashboard": {
    "title": "YYHertz Application Metrics",
    "panels": [
      {
        "title": "HTTP Request Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(yyhertz_http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "histogram",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(yyhertz_http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      }
    ]
  }
}
```

## æ—¥å¿—ç›‘æ§

### ELK Stacké›†æˆ

#### Logstashé…ç½®

```ruby
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][app] == "yyhertz" {
    json {
      source => "message"
    }
    
    date {
      match => [ "timestamp", "ISO8601" ]
    }
    
    mutate {
      add_field => { "application" => "yyhertz" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "yyhertz-%{+YYYY.MM.dd}"
  }
}
```

#### Filebeaté…ç½®

```yaml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/yyhertz/*.log
  fields:
    app: yyhertz
  fields_under_root: true

output.logstash:
  hosts: ["logstash:5044"]
```

## å‘Šè­¦è§„åˆ™

### Prometheuså‘Šè­¦

```yaml
# alerts.yml
groups:
- name: yyhertz.rules
  rules:
  - alert: HighErrorRate
    expr: rate(yyhertz_http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value }} requests per second"

  - alert: HighResponseTime
    expr: histogram_quantile(0.95, rate(yyhertz_http_request_duration_seconds_bucket[5m])) > 1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High response time detected"
      description: "95th percentile response time is {{ $value }}s"

  - alert: ApplicationDown
    expr: up{job="yyhertz"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "YYHertz application is down"
      description: "YYHertz application has been down for more than 1 minute"
```

### Alertmanageré…ç½®

```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@yourdomain.com'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

receivers:
- name: 'web.hook'
  email_configs:
  - to: 'admin@yourdomain.com'
    subject: 'YYHertz Alert: {{ .GroupLabels.alertname }}'
    body: |
      {{ range .Alerts }}
      Alert: {{ .Annotations.summary }}
      Description: {{ .Annotations.description }}
      {{ end }}
  
  slack_configs:
  - api_url: 'https://hooks.slack.com/services/...'
    channel: '#alerts'
    title: 'YYHertz Alert'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
```

## å¥åº·æ£€æŸ¥

### åº”ç”¨å¥åº·æ£€æŸ¥

```go
func HealthCheckHandler(c *gin.Context) {
    health := map[string]interface{}{
        "status": "ok",
        "timestamp": time.Now(),
        "version": version.Version,
    }

    // æ•°æ®åº“å¥åº·æ£€æŸ¥
    if err := db.Ping(); err != nil {
        health["database"] = "unhealthy"
        health["status"] = "degraded"
    } else {
        health["database"] = "healthy"
    }

    // Rediså¥åº·æ£€æŸ¥
    if err := redisClient.Ping().Err(); err != nil {
        health["redis"] = "unhealthy"
        health["status"] = "degraded"
    } else {
        health["redis"] = "healthy"
    }

    status := 200
    if health["status"] == "degraded" {
        status = 503
    }

    c.JSON(status, health)
}
```

### Kubernetesæ¢é’ˆ

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 5
  failureThreshold: 3
```

## æ€§èƒ½ç›‘æ§

### APMé›†æˆ

```go
// Jaegeråˆ†å¸ƒå¼è¿½è¸ª
import "github.com/opentracing/opentracing-go"

func TracingMiddleware() gin.HandlerFunc {
    return gin.HandlerFunc(func(c *gin.Context) {
        span := opentracing.StartSpan(c.Request.URL.Path)
        defer span.Finish()
        
        span.SetTag("http.method", c.Request.Method)
        span.SetTag("http.url", c.Request.URL.String())
        
        c.Set("tracing-span", span)
        c.Next()
        
        span.SetTag("http.status_code", c.Writer.Status())
    })
}
```

### è‡ªå®šä¹‰æŒ‡æ ‡

```go
// ä¸šåŠ¡æŒ‡æ ‡æ”¶é›†
var (
    userRegistrations = promauto.NewCounter(prometheus.CounterOpts{
        Name: "yyhertz_user_registrations_total",
        Help: "Total number of user registrations",
    })
    
    ordersProcessed = promauto.NewCounterVec(
        prometheus.CounterOpts{
            Name: "yyhertz_orders_processed_total",
            Help: "Total number of orders processed",
        },
        []string{"status"},
    )
)

func (c *UserController) Register() {
    // ä¸šåŠ¡é€»è¾‘
    
    // æŒ‡æ ‡è®°å½•
    userRegistrations.Inc()
}
```

å®Œæ•´çš„ç›‘æ§å‘Šè­¦ä½“ç³»ï¼Œç¡®ä¿åº”ç”¨ç¨³å®šè¿è¡Œï¼